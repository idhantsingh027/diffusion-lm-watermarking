What is watermarking?

It is protecting models from various intellectual property violations like copyright infringement, unauthorized use and modification of the model.
Model owners must be aware of these potential risks.

What are diffusion models (DMs)?

They are generative models that generate realistic images through a sequential denoising process.
But they are not secure by design. They may be susceptible to potential misuse, theft of intellectual property.
This can lead to loss of revenue and reputation of the owner. It may enable the attacker to abuse the model such as generating fake images or videos.

Why watermark diffusion models?

Watermarking presents a viable solution by embedding a unique identifier or signature into the model, which enables the identification of the original owner or authorized users of the model reliably.
Watermarking machine learning (ML) models involves injecting perturbations (disturbances) unique to the owner into the model.
Perturbations doesn't affect the accurracy or performance, but can used to identify the original owner if the model is stolen or copied without permission.
Therefore, watermarking provides a degree of protection for models.